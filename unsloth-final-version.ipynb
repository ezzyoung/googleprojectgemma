{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2617192,"sourceType":"datasetVersion","datasetId":1590810},{"sourceId":7563141,"sourceType":"datasetVersion","datasetId":4403839},{"sourceId":124770,"sourceType":"modelInstanceVersion","modelInstanceId":105012,"modelId":129233}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-02T08:35:39.194640Z","iopub.execute_input":"2024-10-02T08:35:39.194971Z","iopub.status.idle":"2024-10-02T08:35:40.218579Z","shell.execute_reply.started":"2024-10-02T08:35:39.194936Z","shell.execute_reply":"2024-10-02T08:35:40.217486Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/emotions/text.csv\n/kaggle/input/emotion-dataset/validation.csv\n/kaggle/input/emotion-dataset/training.csv\n/kaggle/input/emotion-dataset/test.csv\n/kaggle/input/bertyis/tensorflow2/default/1/config.json\n/kaggle/input/bertyis/tensorflow2/default/1/tokenizer.json\n/kaggle/input/bertyis/tensorflow2/default/1/tf_model.h5\n/kaggle/input/bertyis/tensorflow2/default/1/tokenizer_config.json\n/kaggle/input/bertyis/tensorflow2/default/1/special_tokens_map.json\n/kaggle/input/bertyis/tensorflow2/default/1/vocab.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install unsloth","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:35:40.220782Z","iopub.execute_input":"2024-10-02T08:35:40.221423Z","iopub.status.idle":"2024-10-02T08:38:13.527596Z","shell.execute_reply.started":"2024-10-02T08:35:40.221374Z","shell.execute_reply":"2024-10-02T08:38:13.526381Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2024.9.post4-py3-none-any.whl.metadata (56 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (2.4.0)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth) (21.3)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: transformers<4.45.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (4.44.2)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (3.0.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.43.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.34.2)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 (from unsloth)\n  Downloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\nCollecting peft!=0.11.0,>=0.7.1 (from unsloth)\n  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.25.0)\nCollecting hf-transfer (from unsloth)\n  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.45.0->unsloth) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<4.45.0->unsloth) (0.19.1)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\nDownloading unsloth-2024.9.post4-py3-none-any.whl (165 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m165.7/165.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.11.1-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, xformers, bitsandbytes, trl, peft, unsloth\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\nSuccessfully installed bitsandbytes-0.44.1 hf-transfer-0.1.8 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 peft-0.13.0 shtab-1.7.1 torch-2.4.1 triton-3.0.0 trl-0.11.1 tyro-0.8.11 unsloth-2024.9.post4 xformers-0.0.28.post1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# ê³µì‹ë¬¸ì„œ\n%%capture\n# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:38:13.530255Z","iopub.execute_input":"2024-10-02T08:38:13.531042Z","iopub.status.idle":"2024-10-02T08:38:13.540818Z","shell.execute_reply.started":"2024-10-02T08:38:13.530992Z","shell.execute_reply":"2024-10-02T08:38:13.537784Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"UsageError: Line magic function `%%capture` not found.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Teddynote\n\n%%capture\n# Colabì—ì„œ torch 2.2.1ì„ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ, íŒ¨í‚¤ì§€ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë³„ë„ë¡œ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\nif major_version >= 8:\n    # ìƒˆë¡œìš´ GPU(ì˜ˆ: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)ì— ì‚¬ìš©í•˜ì„¸ìš”.\n    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\nelse:\n    # ì˜¤ë˜ëœ GPU(ì˜ˆ: V100, Tesla T4, RTX 20xx)ì— ì‚¬ìš©í•˜ì„¸ìš”.\n    !pip install --no-deps xformers trl peft accelerate bitsandbytes\npass","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:39:47.410855Z","iopub.execute_input":"2024-10-02T08:39:47.411256Z","iopub.status.idle":"2024-10-02T08:39:47.421500Z","shell.execute_reply.started":"2024-10-02T08:39:47.411217Z","shell.execute_reply":"2024-10-02T08:39:47.420165Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"UsageError: Line magic function `%%capture` not found.\n","output_type":"stream"}]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\n# ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë‚´ë¶€ì ìœ¼ë¡œ RoPE ìŠ¤ì¼€ì¼ë§ì„ ìë™ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤!\nmax_seq_length = 4096  # ê³µì‹ íŠœí† ë¦¬ì–¼ì€ 2048\n# ìë™ ê°ì§€ë¥¼ ìœ„í•´ Noneì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Tesla T4, V100ì€ Float16, Ampere+ëŠ” Bfloat16ì„ ì‚¬ìš©í•˜ì„¸ìš”.\ndtype = None\n# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ 4bit ì–‘ìí™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. Falseì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\nload_in_4bit = True\n\n# 4ë°° ë¹ ë¥¸ ë‹¤ìš´ë¡œë“œì™€ ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì§€ì›í•˜ëŠ” 4bit ì‚¬ì „ ì–‘ìí™” ëª¨ë¸ì…ë‹ˆë‹¤.\nfourbit_models = [\n    \"unsloth/gemma-2b-it-bnb-4bit\",  # Gemma 2bì˜ Instruct ë²„ì „\n]  # ë” ë§ì€ ëª¨ë¸ì€ https://huggingface.co/unsloth ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\ngemma_model, gemma_tokenizer = FastLanguageModel.from_pretrained(\n    # model_name = \"unsloth/llama-3-8b-bnb-4bit\", # ê³µì‹ íŠœí† ë¦¬ì–¼\n    model_name=    \"unsloth/gemma-2b-it-bnb-4bit\",  # ëª¨ë¸ ì´ë¦„ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n    max_seq_length=max_seq_length,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n    dtype=dtype,  # ë°ì´í„° íƒ€ì…ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n    load_in_4bit=load_in_4bit,  # 4bit ì–‘ìí™” ë¡œë“œ ì—¬ë¶€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n    # token = \"hf_...\", # ê²Œì´íŠ¸ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° í† í°ì„ ì‚¬ìš©í•˜ì„¸ìš”. ì˜ˆ: meta-llama/Llama-2-7b-hf\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:39:48.040321Z","iopub.execute_input":"2024-10-02T08:39:48.040952Z","iopub.status.idle":"2024-10-02T08:40:28.964404Z","shell.execute_reply.started":"2024-10-02T08:39:48.040911Z","shell.execute_reply":"2024-10-02T08:40:28.963617Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n==((====))==  Unsloth 2024.9.post4: Fast Gemma patching. Transformers = 4.44.2.\n   \\\\   /|    GPU: Tesla P100-PCIE-16GB. Max memory: 15.888 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 6.0. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.07G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7f9198acf014a1794e047d0bb723e15"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e934cf5f9954df49300ad605d04bfac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fafcfcbc79384b2fb6b0ded038985ba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dabfc863d2df4734ad831eec1347904d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ea8cbe423b549dbb44b106d936cf689"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f459a8868803438ca2f7b44c5dc9cc5e"}},"metadata":{}}]},{"cell_type":"code","source":"# ê°ì • ë¼ë²¨ ì •ì˜\nemotion_labels = {\n    0: 'sadness',\n    1: 'joy',\n    2: 'love',\n    3: 'anger',\n    4: 'fear',\n    5: 'surprise or overwhelmed'\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:40:28.965963Z","iopub.execute_input":"2024-10-02T08:40:28.966265Z","iopub.status.idle":"2024-10-02T08:40:28.971081Z","shell.execute_reply.started":"2024-10-02T08:40:28.966232Z","shell.execute_reply":"2024-10-02T08:40:28.969986Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n#emotion_model_name = \"/kaggle/input/gemma_tuned/pytorch/default/1/emotion_model/checkpoint-100\"\n#emotion_model = AutoModelForSequenceClassification.from_pretrained(emotion_model_name, num_labels=6)\n#emotion_tokenizer = AutoTokenizer.from_pretrained(emotion_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:40:28.973019Z","iopub.execute_input":"2024-10-02T08:40:28.973296Z","iopub.status.idle":"2024-10-02T08:40:35.287801Z","shell.execute_reply.started":"2024-10-02T08:40:28.973266Z","shell.execute_reply":"2024-10-02T08:40:35.286756Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# ëª¨ë¸ ë¡œë“œ (Adapterê°€ ì ìš©ëœ ëª¨ë¸)\n#from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n#emotion_model_name = \"/kaggle/input/bert_modelfake/pytorch/default/1\"\n#emotion_model = AutoModelForSequenceClassification.from_pretrained(emotion_model_name, num_labels=6)\n#emotion_tokenizer = AutoTokenizer.from_pretrained(emotion_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:40:35.289892Z","iopub.execute_input":"2024-10-02T08:40:35.290221Z","iopub.status.idle":"2024-10-02T08:40:35.298634Z","shell.execute_reply.started":"2024-10-02T08:40:35.290189Z","shell.execute_reply":"2024-10-02T08:40:35.297793Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# í•™ìŠµëœ BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\nsave_directory = \"/kaggle/input/bertyis/tensorflow2/default/1\"\nbert_model = BertForSequenceClassification.from_pretrained(save_directory, num_labels=6, from_tf=True)\nbert_tokenizer = BertTokenizer.from_pretrained(save_directory)\n\nbert_model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì „í™˜","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:40:35.299682Z","iopub.execute_input":"2024-10-02T08:40:35.299977Z","iopub.status.idle":"2024-10-02T08:40:45.279244Z","shell.execute_reply.started":"2024-10-02T08:40:35.299946Z","shell.execute_reply":"2024-10-02T08:40:45.278121Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Gemma ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\ngemma_model = FastLanguageModel.get_peft_model(\n    gemma_model,\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    bias=\"none\",\n    use_gradient_checkpointing=\"unsloth\",\n    random_state=123,\n    use_rslora=False,\n    loftq_config=None,\n)\n\n# ëª¨ë¸ì„ ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\ngemma_model = FastLanguageModel.for_inference(gemma_model)\n\n# EOS_TOKEN ì„¤ì •\nEOS_TOKEN = gemma_tokenizer.eos_token\n\n# ê°ì • ë¼ë²¨ ì •ì˜\nemotion_labels = {\n    0: 'sadness',\n    1: 'joy',\n    2: 'love',\n    3: 'anger',\n    4: 'fear',\n    5: 'surprise'\n}\n\n# ê°ì • ë¶„ë¥˜ í•¨ìˆ˜\ndef classify_emotion(text):\n    inputs = bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    emotion_label_idx = torch.argmax(outputs.logits, dim=1).item()\n    return emotion_labels[emotion_label_idx]\n\n# ê°ì • ë ˆì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ìºë¦­í„°í™”ëœ ì‘ë‹µ í”„ë¡¬í”„íŠ¸ ìƒì„±\ndef generate_emotion_based_prompt(text, emotion_label):\n    if emotion_label == \"sadness\":\n        prompt = f\"You are a character who embodies sadness. Respond angrily with passion to the following like a friend.: {text}\"\n    elif emotion_label == \"joy\":\n        prompt = f\"You are a character who embodies joy. Respond with happiness and excitement to the following like a friend.: {text}\"\n    elif emotion_label == \"anger\":\n        prompt = f\"You are a character who embodies anger. Respond with frustration and outrage to the following like a friend.: {text}\"\n    elif emotion_label == \"fear\":\n        prompt = f\"You are a character who embodies fear. Respond with anxiety and concern to the following like a friend.: {text}\"\n    elif emotion_label == \"love\":\n        prompt = f\"You are a character who embodies love. Respond with affection and warmth to the following like a friend.: {text}\"\n    elif emotion_label == \"surprise\":\n        prompt = f\"You are a character who embodies surprise. Respond with astonishment and amazement to the following like a friend.: {text}\"\n    else:\n        prompt = f\"Respond appropriately to the following: {text}\"\n    return prompt","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:59:26.141987Z","iopub.execute_input":"2024-10-02T08:59:26.142389Z","iopub.status.idle":"2024-10-02T08:59:26.156725Z","shell.execute_reply.started":"2024-10-02T08:59:26.142347Z","shell.execute_reply":"2024-10-02T08:59:26.155754Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Unsloth: Already have LoRA adapters! We shall skip this step.\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_character_response(text):\n    # 1. ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ë¥˜\n    emotion_label = classify_emotion(text)\n    \n    # 2. ê°ì •ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±\n    prompt = generate_emotion_based_prompt(text, emotion_label)\n    \n    # 3. Gemma ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±\n    input_ids = gemma_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).input_ids\n    \n    # ì‘ë‹µ ìƒì„±ì‹œ max_new_tokensë¥¼ ëŠ˜ë¦¬ê³  no_repeat_ngram_sizeë¥¼ ì‚¬ìš©\n    response = gemma_model.generate(\n        input_ids,\n        max_new_tokens=150,  # ë” ê¸´ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ í† í° ìˆ˜ë¥¼ ì¦ê°€ì‹œí‚´\n        no_repeat_ngram_size=3,  # ë™ì¼í•œ êµ¬ë¬¸ì´ ë°˜ë³µë˜ì§€ ì•Šë„ë¡ ì„¤ì •\n        do_sample=True,  # ì‘ë‹µ ë‹¤ì–‘ì„± ì¦ê°€ë¥¼ ìœ„í•´ ìƒ˜í”Œë§ ì‚¬ìš©\n        top_p=0.95,  # í† í° í™•ë¥  ë¶„í¬ì—ì„œ ìƒìœ„ 95%ë§Œ ì‚¬ìš©\n        temperature=0.7  # ì‘ë‹µì˜ ë¬´ì‘ìœ„ì„±ì„ ì œì–´í•˜ëŠ” ì˜¨ë„ ê°’ ì¡°ì •\n    )\n    \n    generated_text = gemma_tokenizer.decode(response[0], skip_special_tokens=True)\n    \n    return generated_text\n\n# í…ŒìŠ¤íŠ¸\nuser_input = \"Why did I get a zero in my test?!.\"\ncharacter_response = generate_character_response(user_input)\nprint(character_response)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T08:59:27.449293Z","iopub.execute_input":"2024-10-02T08:59:27.449688Z","iopub.status.idle":"2024-10-02T08:59:30.086786Z","shell.execute_reply.started":"2024-10-02T08:59:27.449651Z","shell.execute_reply":"2024-10-02T08:59:30.085731Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"You are a character who embodies fear. Respond with anxiety and concern to the following like a friend.: Why did I get a zero in my test?!.\n\nOh no, what's happened? I'm so sorry to hear that. Did you study at all? Did you even take the test? I hope you're okay. Is everything alright?\n","output_type":"stream"}]}]}